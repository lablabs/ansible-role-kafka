broker.id=-1
zookeeper.connect={% for node in kafka_zookeeper_nodes %}{{ node }}:{{ kafka_zookeeper_port }}{{ "," if not loop.last else "" }}{% endfor %}
{% if kafka_zookeeper_chroot is defined -%}
{{ kafka_zookeeper_chroot }}
{% endif %}
advertised.listeners=PLAINTEXT://{{ kafka_advertised_ip }}:{{ kafka_advertised_port }}
listeners=PLAINTEXT://0.0.0.0:{{ kafka_advertised_port }}
log.dirs={{ kafka_log_dirs }}
broker.rack={{ hostvars[inventory_hostname]['placement']['availability_zone'] }}
num.network.threads={{ kafka_props_num_network_threads }}
num.io.threads={{ kafka_props_num_io_threads }}
num.partitions={{ kafka_props_num_partitions }}
socket.send.buffer.bytes={{ kafka_props_socket_send_buffer_bytes }}
socket.receive.buffer.bytes={{ kafka_props_socket_receive_buffer_bytes }}
socket.request.max.bytes={{ kafka_props_socket_request_max_bytes }}
num.recovery.threads.per.data.dir={{ kafka_props_num_recovery_threads_per_data_dir }}
offsets.topic.replication.factor={{ kafka_props_offsets_topic_replication_factor }}
transaction.state.log.replication.factor={{ kafka_props_transaction_state_log_replication_factor }}
transaction.state.log.min.isr={{ kafka_props_transaction_state_log_min_isr }}
log.retention.hours={{ kafka_props_log_retention_hours }}
log.segment.bytes={{ kafka_props_log_segment_bytes }}
log.retention.check.interval.ms={{ kafka_props_log_retention_check_interval_ms }}
zookeeper.connection.timeout.ms={{ kafka_props_zookeeper_connection_timeout_ms }}
group.initial.rebalance.delay.ms={{ kafka_props_group_initial_rebalance_delay_ms }}
delete.topic.enable={{ kafka_props_delete_topic_enable }}
auto.create.topics.enable={{ kafka_props_auto_create_topics_enable }}
default.replication.factor={{ kafka_props_default_replication_factor }}
inter.broker.protocol.version={{ kafka_props_inter_broker_protocol_version }}
